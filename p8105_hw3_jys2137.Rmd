---
title: "Homework 3"
author: "jys2137"
date: "10/14/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 6, 
	fig.asp = .6,
  fig.height = 6,
	dpi = 300,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

The purpose of this file is to present the answers to Homework 3, an assignment reinforcing ideas in the **Visualization & EDA** topic for P8105. 

## Problem 1
This problem uses **"The Instacart Online Grocery Shopping Dataset 2017"**, an anonymized dataset with over 3 million online grocery orders from more than 200,000 Instacart (online grocery service) users.

### 1.1. Loading in `instacart` dataset
First, we read in the `instacart` dataset through the code chunk below.

```{r load_instacart}
data("instacart")

instacart_df = 
  instacart %>% 
  as_tibble(instacart)

instacart_df
```

### 1.2. Description of the `instacart` dataset

The 'Instacart' dataset includes **`r nrow(instacart)` rows** and **`r ncol(instacart)` variables**, where each row in the dataset is a product from an instacart order. It consists of **`r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders** from **`r instacart %>% select(user_id) %>% distinct %>% count` unique users**, including a total of **`r instacart %>% select(product_id) %>% distinct %>% count` products**.

Key variables include identifiers for **order** (`order_id`), **product** (`product_id`), and **customer** (`user_id`). Other variables provide information on the order such as the order in which each product was added to cart (`add_to_cart_order`), if the product has been reordered in the past (`reordered`), and the day and time on which the order was placed (`order_dow`and `order_hour_of_day`). 

In addition, variables containing the specifics of each product were included such as the name (e.g., "Bulgarian Yogurt", "Mild Diced Green Chiles", "Organic Raspberries"), aisle (e.g. "yogurt", "canned jarred vegetables", packaged vegetables fruits"), and department of the product (e.g., "dairy eggs","canned goods", "produce").

### 1.3. Exploration of _aisles_ in the `instacart` dataset
The next few steps allow for further exploration of the `instacart` dataset as we look into:

1. Number of aisles and aisles most ordered from
2. Number of items from each aisle
3. Most popular items in each of the aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`


#### 1.3.1. Number of _aisles_ and those most ordered from

There are **`r instacart %>% select(aisle) %>% distinct %>% count` aisles** in total. The aisles most ordered from are `fresh vegetables` and `fresh fruits` as seen in the table produced below, which shows the top 10 aisles that most items are ordered from.

```{r aisle_table}
instacart_df %>% 
  count(aisle) %>% 
  arrange(desc(n)) %>% 
  head(n = 10) %>% 
  mutate(row_number = 1:n()) %>% 
  select(row_number, aisle, n) %>% 
  knitr::kable(
             caption = "_**Fig. 1. Top 10 Aisles Most Ordered From**_",
             col.names = c('Rank', 'Aisle', 'N'),
             align = "clc")
```

#### 1.3.2. Number of _items_ from each aisle 

Next, we produce a plot that shows the number of items ordered in each aisle. Only aisles with more than 10000 items ordered are included.

```{r aisle_plot, fig.width=8, message = FALSE}
instacart_df %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n, fill = aisle)) + 
  geom_bar(stat = "identity", alpha = .75) +
  coord_flip() +
  theme(
    axis.text.x = element_text(angle = -35, hjust = 0, vjust = .5),
    axis.text.y = element_text(size = 8),
    plot.title = element_text(face = "bold.italic" ),
    legend.position = "none") +
  labs(
    title = "Fig. 2. Number of Instacart Items Ordered by Aisle", 
    x = "Aisle",
    y = "Number of items ordered",
    caption = "Data from Instacart Online Grocery Shopping Dataset 2017") 
```

#### 1.3.3. Most popular items 

Now, we use a table showing the **three most popular items** in each of the aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, including the number of times each item was ordered.

```{r pop_item_table}
pop_item =
  instacart_df %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", 
                      "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>%
  mutate(rank = rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  mutate(product_name_count = paste(product_name, "-", "ordered", n, "times")) %>%
  select(-n, -product_name) %>% 
  arrange(rank) %>% 
  pivot_wider(
    names_from = aisle, 
    values_from = product_name_count)

knitr::kable(pop_item,
             caption = "_**Fig. 3. Top 3 Items Ordered by Aisle**_", 
             col.names = str_to_title(names(pop_item)),
             align = "clll")
```

### 1.4. `Pink Lady Apples` and `Coffee Ice Cream`

Here, a table is used to show the **mean hour** of the day at which `Pink Lady Apples` and `Coffee Ice Cream` are ordered on **each day** of the week. This table has been formatted for human readers (2 x 7 table).

```{r pink_coff_table, message = FALSE}
pink_coff_table = 
  instacart_df %>%
  group_by(product_name, order_dow) %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  mutate(order_dow = recode(order_dow, 
                            `0` = "Sun", `1` = "Mon", `2` = "Tues", 
                            `3` = "Wed", `4` = "Thurs", `5` = "Fri", 
                            `6` = "Sat")) %>% 
  pivot_wider(
    names_from = "order_dow", 
    values_from = "mean_hour") %>%
  arrange(desc(product_name)) %>% 
  rename(Product = product_name) 

  knitr::kable(pink_coff_table,
             digits = 2,
             caption = "_**Fig. 4. Mean Hour of Day for Pink Lady Appples and 
             Coffee Ice Cream**_")
```

From this table, it can be seen that for most days, **pink lady apples** are ordered _earlier in the day_ compared to **coffee ice cream** purchases. However, Friday seems to be the exception when coffee ice cream was ordered slightly earlier than pink lady apples.


## Problem 2
This problem uses data accessed from data.gov from the **Behavioral Risk Factors Surveillance System for Selected Metropolitan Area Risk Trends (SMART) for 2002-2010**, or `BRFSS` for short, which consists of information about modifiable risk factors for chronic diseases and other leading causes of death.

### 2.1. Loading in the `BRFSS` dataset

First, we read in the `BRFSS` dataset and conduct some data cleaning by:

- formatting the data to use appropriate variable names;
- focusing on the “Overall Health” topic
- including only responses from “Excellent” to “Poor”
- organizing responses as a factor taking levels ordered from “Poor” to “Excellent”

```{r BRFSS_read_clean}
data("brfss_smart2010")

brfss_df =
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = as_factor(response)) %>% 
  arrange(desc(response)) %>% 
  rename(state = locationabbr, county = locationdesc)

head(brfss_df)
```

### 2.2. States observed at 7 or more locations in 2002 and 2010

Using the `BRFSS` dataset, we will create a table of states observed at 7 or more locations in 2002 and 2010.

```{r states_observed, message = FALSE}
brfss_states =
  brfss_df %>% 
  group_by(year, state) %>% 
  summarize(num_locations = n()) %>% 
  filter(year %in% c(2002, 2010), 
         num_locations >= 7) %>% 
  pivot_wider(names_from = year, values_from = num_locations) %>% 
  arrange(state)

knitr::kable(brfss_states,
             col.names = c("State", "2002", "2010"),
             caption = "_**Fig. 5. States observed at 7 or more locations in 2002 
                        and 2010**_")
```

In _2002_, there were **`r nrow(brfss_states %>% select("2002") %>% drop_na())` states** that were observed at 7 or more locations while in _2010_, there were **`r nrow(brfss_states %>% select("2010") %>% drop_na())` states** with 7 or more observation locations.

### 2.3. Spaghetti plot 

The following code chunk establishes a dataset that is:

- limited to Excellent responses; and
- contains `year`, `state`, and `mean_data_value` (a variable that averages the `data_value` across locations within a state)

This also creates a “spaghetti” plot of this average value over time within a state (showing a line for each state across years).

```{r brfss_spaghetti, warning = FALSE}
brfss_df %>% 
  filter(response == "Excellent") %>% 
  group_by(year, state) %>% 
  summarize(mean_data_value = mean(data_value)) %>% 
  ggplot(aes(x = year, y = mean_data_value, group = state, color = state)) +
  geom_line() +
  scale_color_viridis_d() +
  labs(x = "Year", 
       y = "Mean Data Value", 
       title = "Fig. 6. Mean Data Value by State") +
  theme(
    plot.title = element_text(face = "bold.italic"),
    legend.position = "right")
```

### 2.4. Distribution of `data_value` in NY

Next, we develop a two-panel plot showing, for the years 2006 and 2010, distribution of `data_value` for responses (“Poor” to “Excellent”) among locations in NY State.

```{r brfss_ny_plot, fig.height=5, fig.width=7}
brfss_df %>% 
  filter(
    year %in% c(2006, 2010), 
    state %in% c("NY")) %>% 
  ggplot(aes(x = response, y = data_value, color = response)) +
  geom_boxplot() +
  geom_jitter(width = 0.25, alpha = 0.75) +
  facet_grid(~year) +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = -35, hjust = 0, vjust = .5),
    plot.title = element_text(face = "bold.italic")) +
  labs(
    x = "Response", 
    y = "Data Value", 
    title = "Fig. 7. Distributions of Data Value in NY")
```

## Problem 3

This problem uses five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF).

### 3.1. Loading in the `accel` dataset

Here, we load, tidy, and wrangle the `accel` data. This final dataset:

- includes all originally observed variables and values
- has useful variable names
- includes a `weekday` vs `weekend` variable
- encodes data with reasonable variable classes

```{r accel_df_clean, message = FALSE}
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_", 
    values_to = "activity_count") %>% 
  mutate(
    minute = as.numeric(minute),
    day = factor(day, levels = c("Sunday", "Monday", "Tuesday", 
                                 "Wednesday","Thursday", "Friday", "Saturday")),
    weekday_weekend = as.numeric(day %in% c("Saturday", "Sunday")),
    weekday_weekend = recode(weekday_weekend, 
                             `0` = "weekday", `1` = "weekend"))

head(accel_df)
```

#### Brief description of the final `accel` dataset

The final `accel` dataset includes **`r nrow(accel_df)` observations** and **`r ncol(accel_df)` variables**, which include `week`, `day_id`,`day`, `minute`, `activity_count`, and `weekday_weekend` which signified if the day was a _weekday_ or _weekend._

### 3.2. Total activity for each day

Using the accelerometer data, we create a plot of total activity for each day. We do this by using the previously tidied dataset and aggregating across minutes to create a total activity variable, `activity_tot` for each day, through the code chunk below.

```{r accel_act_table}
act_table =
  accel_df %>% 
  group_by(day, week) %>% 
  summarize(activity_tot = sum(activity_count)) %>% 
  pivot_wider(
    names_from = day, 
    values_from = activity_tot) %>%
  rename(Week = week) 

  knitr::kable(act_table,
             caption = "_**Fig. 8. Total Activity By Day**_",
             align = "cccccccc",
             digit = 0)
```
#### Brief description of apparent trends

The table above indicates that **Saturdays** have the **least activity**, with two Saturdays having a total activity of 1440 minutes. However, for these it looks like there was a possible data collection error -- the value of "1" was input into the total activity variable for each minute in those days. Thus, this might not actually have any inherent value in relation to figuring out whether there are trends that can be pulled out simply from this table. 

In conclusion, there are no clear trends that can be garnered through observation of this table. Instead, additional analyses must be conducted to lend confidence into any possible trend that may exist in average total activity each day throughout the week.

  
### 3.3. Activity time courses by day

Finally, we create a single-panel plot that shows the 24-hour activity time courses for each day and uses color to indicate day of the week. 

```{r accel_plot}
accel_act_plot = 
  accel_df %>% 
  group_by(week,day) %>% 
  ggplot(aes(x = minute, y = activity_count, group = day, color = day)) + 
  geom_line(alpha = .25) + 
  geom_smooth(se = FALSE, size = 1) +
  scale_x_continuous(breaks = c(0, 360, 720, 1080, 1440),
                     labels = c("12am", "6am", "12pm", "6pm", "12am")) +
  scale_colour_discrete(name = "Day of Week") +
  labs(x = "Time of Day", 
       y = "Activity Count", 
       title = "Fig. 9. Accelerometer Activity for Each Day of the Week") +
  theme(plot.title = element_text(face = "bold.italic"))

accel_act_plot
```

In order to better see the trend lines, below we zoom in and can take a closer look.

```{r zoom_accel_act_plot}
accel_act_plot + coord_cartesian(ylim = c(0, 1000)) 
```

#### Conclusions on activity time

Based on this graph, which illustrates activity throughout the each day (colored by day of the week), we can see the following patterns:

- Activity was _**higher** during the day_, and _**lower** at night_, from 12am to 6am. This makes sense, as most people are asleep at those hours and are moving around during the day. 
- There is a _**spike**_ in activity at _noon_, mainly on _Sundays_. This is likely due to people going out for lunch at this time. 
- An additional _**increase**_ in activity takes place on _Friday evenings_ after 6pm. This may be due to people going out and socializing at that time.